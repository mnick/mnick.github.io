<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.44" />
  <meta name="author" content="Maximilian Nickel">

  
  
  
  
    
      
    
  
  <meta name="description" content="Representation learning has become an invaluable approach in machine learning and artificial intelligence. For instance, word embeddings such as word2vec, GloVe and fastText are widely used for tasks rangingfrom machine translation to sentiment analysis. Similarly, embeddings of (multi-)graphs such as RESCAL and node2vec have found important applications for learning in semantic and social networks.
In this project, we study a fundamental aspect of representation learning, i.e., the influence of the underlying geometry on embedding structured data.">

  
  <link rel="alternate" hreflang="en-us" href="/project/geometric-representation-learning/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair&#43;Display:400,700%7cFauna&#43;One">
  
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/maxn.css">
  

  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Maximilian Nickel">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Maximilian Nickel">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/project/geometric-representation-learning/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@https://twitter.com/mnick">
  <meta property="twitter:creator" content="@https://twitter.com/mnick">
  
  <meta property="og:site_name" content="Maximilian Nickel">
  <meta property="og:url" content="/project/geometric-representation-learning/">
  <meta property="og:title" content="Geometric Representation Learning | Maximilian Nickel">
  <meta property="og:description" content="Representation learning has become an invaluable approach in machine learning and artificial intelligence. For instance, word embeddings such as word2vec, GloVe and fastText are widely used for tasks rangingfrom machine translation to sentiment analysis. Similarly, embeddings of (multi-)graphs such as RESCAL and node2vec have found important applications for learning in semantic and social networks.
In this project, we study a fundamental aspect of representation learning, i.e., the influence of the underlying geometry on embedding structured data.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-07-21T00:00:00-04:00">
  
  <meta property="article:modified_time" content="2018-07-21T00:00:00-04:00">
  

  
  

  <title>Geometric Representation Learning | Maximilian Nickel</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Maximilian Nickel</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#workshops">
            
            <span>Workshops &amp; Symposia</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#talks">
            
            <span>Talks &amp; Tutorials</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Geometric Representation Learning</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Geometric%20Representation%20Learning&amp;url=%2fproject%2fgeometric-representation-learning%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fproject%2fgeometric-representation-learning%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fproject%2fgeometric-representation-learning%2f&amp;title=Geometric%20Representation%20Learning"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fproject%2fgeometric-representation-learning%2f&amp;title=Geometric%20Representation%20Learning"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Geometric%20Representation%20Learning&amp;body=%2fproject%2fgeometric-representation-learning%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      <p>Representation learning has become an invaluable approach in machine learning
and artificial intelligence. For instance, word embeddings such as
<a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-andphrases" target="_blank">word2vec</a>,
<a href="https://nlp.stanford.edu/projects/glove/" target="_blank">GloVe</a> and
<a href="https://github.com/facebookresearch/fastText" target="_blank">fastText</a> are widely used for
tasks rangingfrom machine translation to sentiment analysis. Similarly,
embeddings of (multi-)graphs such as
<a href="/project/knowledge-graph-embeddings">RESCAL</a> and
<a href="https://snap.stanford.edu/node2vec/" target="_blank">node2vec</a> have found important
applications for learning in semantic and social networks.</p>

<p>In this project, we study a fundamental aspect of
representation learning, i.e., the <strong>influence of the underlying geometry on
embedding structured data</strong>. This spans research areas such as <em>machine learning in
non-Euclidean geometries</em>, <em>Riemannian geometry and optimization</em>, <em>graph theory</em>, as well as
<em>representation learning for structured data</em>.</p>

<p>One motivation for this project is that many complex symbolic
datasets (e.g., text corpora, networks) are characterized by <em>latent hierarchies</em>.
However, modeling such hierarchical structures in Euclidean space
requires large embedding dimensions which, in turn, causes significant problems
with regard to the computational complexity and the representation capacity of such
embeddings.</p>

<p>Moreover, finding a way to represent hierarchies explicitly in an
embedding space can be very beneficial to solve complex tasks in artificial
intelligence such as reasoning, lexical entailment, or few- and zero-shot
learning.</p>

<figure>

<img src="/img/ca-condmat.png" alt="Figure 1: Tree-like structure of a scientific collaboration network." width="50%" />



<figcaption data-pre="Figure " data-post=":" >
  <p>
    Figure 1: Tree-like structure of a scientific collaboration network.
    
    Image by Aaron Adcock.
    
  </p> 
</figcaption>

</figure>

<p>In our work on <a href="/tags/hyperbolic-embeddings/">hyperbolic embeddings</a>, we
introduce a novel approach for <strong>learning hierarchical representations</strong> by
embedding entities into hyperbolic space. Due to its geometry, hyperbolic space
can be thought of as a <em>continuous version of trees</em> what allows us to learn
parsimonious representations that simultaneously capture hierarchy and
similarity. This a leads to significant improvements in terms of representation
capacity and generalization ability on data with latent hierarchies. For
instance, Figure 2 illustrates how efficient large hierarchies such
as the WordNet noun taxonomy can be embedded in hyperbolic space.</p>

<figure>

<img src="/img/wn-nouns.jpg" alt="Figure 2: Embedding of the WordNet noun hierarchy into a 2-dimensional hyperbolic space" width="90%" />



<figcaption data-pre="Figure " data-post=":" >
  <p>
    Figure 2: Embedding of the WordNet noun hierarchy into a 2-dimensional hyperbolic space
    
    
    
  </p> 
</figcaption>

</figure>

<p>Moreover, due to the hierarchical nature of hyperbolic space we can identify
hierarchical relationships directly from the embedding. In our <a href="/publications/nickel2018learning">ICML&rsquo;18
paper</a>, we used this property to discover
hierarchies from similarity measurements. For instance, the image below shows an
embedding of language similarities in hyperbolic space. It can be seen that the embedding does not only reflect the different language clusters nicely, but also captures the historical relationships between
languages (where older languages are closer to the center of the disc).</p>

<figure>

<img src="/img/cognate.jpg" alt="Figure 3: Discovering historical relationships between languages by embedding cognate similiarity scores in hyperbolic space" width="95%" />



<figcaption data-pre="Figure " data-post=":" >
  <p>
    Figure 3: Discovering historical relationships between languages by embedding cognate similiarity scores in hyperbolic space
    
    
    
  </p> 
</figcaption>

</figure>

<p>Code to compute Poincaré embeddings is available on
<a href="https://github.com/facebookresearch/poincare-embeddings" target="_blank">Github</a>. Code to
comute embeddings in the Lorentz model, as proposed in our recent paper, will
follow soon.</p>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/hyperbolic-embeddings/">hyperbolic-embeddings</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/representation-learning/">representation-learning</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/graphs-and-networks/">graphs-and-networks</a>
  
</div>




    
    
    

    
      
      
      
      
        <h2>Publications</h2>
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    Maximilian Nickel, Douwe Kiela</span>.
  <a href="/publication/nickel2018learning/" itemprop="name">Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry</a>.
  ICML,
  2018.
  <p>




<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1806.03417" target="_blank" rel="noopener">
  PDF
</a>








  
  <a class="btn btn-primary btn-outline btn-xs" href="/project/geometric-representation-learning/">
    Project
  </a>
  







</p>
</div>

          
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    Maximilian Nickel, Douwe Kiela</span>.
  <a href="/publication/nickel2017poincare/" itemprop="name">Poincaré Embeddings for Learning Hierarchical Representations</a>.
  NIPS,
  2017.
  <p>




<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1705.08039" target="_blank" rel="noopener">
  PDF
</a>




<button type="button" class="btn btn-primary btn-outline btn-xs js-cite-modal"
        data-filename="/files/citations/nickel2017poincare.bib">
  Cite
</button>


<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/facebookresearch/poincare-embeddings" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-primary btn-outline btn-xs" href="/project/geometric-representation-learning/">
    Project
  </a>
  





<a class="btn btn-primary btn-outline btn-xs" href="https://www.facebook.com/nipsfoundation/videos/1553634558061111/" target="_blank" rel="noopener">
  Video
</a>



</p>
</div>

          
        
      

      
      
      
      
        <h2>Talks</h2>
        
          <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/Event">
  <i class="fa fa-comment-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name"><a href="/talk/cern2018/">Poincaré Embeddings for Learning Hierarchical Representations</a></span>
  <div itemprop="startDate">
    
    Feb 28, 2018
    
      11:00 AM
    
  </div>
  <div class="talk-metadata">
    
            CERN Data science seminar
    
  </div>
  <div class="talk-links">
    





<a class="btn btn-primary btn-outline btn-xs" href="https://cds.cern.ch/record/2306315">
  Video
</a>



  
  <a class="btn btn-primary btn-outline btn-xs" href="/project/geometric-representation-learning/">
    Project
  </a>
  



  </div>
</div>

        
      
    

  </div>
</article>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

